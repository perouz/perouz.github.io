@inproceedings{Xu2023sparsity,
 abstract = {Causal representation learning (CRL) aims at identifying high-level causal variables from low-level data, e.g. images. Current methods usually assume that all causal variables are captured in the high-dimensional observations. In this work, we focus on learning causal representations from data under partial observability, i.e., when some of the causal variables are not observed in the measurements, and the set of masked variables changes across the different samples. We introduce some initial theoretical results for identifying causal variables under partial observability by exploiting a sparsity regularizer, focusing in particular on the linear and piecewise linear mixing function case. We provide a theorem that allows us to identify the causal variables up to permutation and element-wise linear transformations in the linear case and a lemma that allows us to identify causal variables up to linear transformation in the piecewise case. Finally, we provide a conjecture that would allow us to identify the causal variables up to permutation and element-wise linear transformations also in the piecewise linear case.We test the theorem and conjecture on simulated data, showing the effectiveness of our method.},
 author = {Danru Xu and Dingling Yao and SÃ©bastien Lachapelle and Perouz Taslakian and Julius Von K\:uglen and Francesco Locatello and Sara Magliacane},
 booktitle = {Proceedings of NeurIPS Workshop on Causal Representation Learning},
 title = {A Sparsity Principle for Partially Observable Causal Representation Learning},
 year = {2023}
}

